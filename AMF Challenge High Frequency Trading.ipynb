{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Group Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members:\n",
    "    - Mouhaned Yousef\n",
    "    - Brendan Bouchaud\n",
    "    - Thomas Grimault\n",
    "    - Elias Essaadouni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project has as an objective to multicalss classification, throughout testing 3 neural network and testing the accuracy of each.\n",
    "In this project we are using a dataset which has 3 types of traders (High Frequency Traders, Non High Frequency Traders and Mix) and the features of each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the dataset\n",
    "Data = pd.read_csv('AMF_DATA.csv')\n",
    "# This dataset contains a number of cells with no value thus we have decided to drop the Nan rather than to impute\n",
    "Data = Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Index</th>\n",
       "      <th>OTR</th>\n",
       "      <th>OCR</th>\n",
       "      <th>OMR</th>\n",
       "      <th>min_time_two_events</th>\n",
       "      <th>mean_time_two_events</th>\n",
       "      <th>10_p_time_two_events</th>\n",
       "      <th>med_time_two_events</th>\n",
       "      <th>25_p_time_two_events</th>\n",
       "      <th>...</th>\n",
       "      <th>min_dt_TV1_TV2</th>\n",
       "      <th>mean_dt_TV1_TV2</th>\n",
       "      <th>med_dt_TV1_TV2</th>\n",
       "      <th>min_dt_TV1_TV3</th>\n",
       "      <th>mean_dt_TV1_TV3</th>\n",
       "      <th>med_dt_TV1_TV3</th>\n",
       "      <th>min_dt_TV1_TV4</th>\n",
       "      <th>mean_dt_TV1_TV4</th>\n",
       "      <th>med_dt_TV1_TV4</th>\n",
       "      <th>NbSecondWithAtLeatOneTrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "      <td>43817.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57210.301618</td>\n",
       "      <td>57211.301618</td>\n",
       "      <td>28.384754</td>\n",
       "      <td>12.244495</td>\n",
       "      <td>202.309402</td>\n",
       "      <td>0.102265</td>\n",
       "      <td>1329.763761</td>\n",
       "      <td>4.158810</td>\n",
       "      <td>404.011596</td>\n",
       "      <td>67.036790</td>\n",
       "      <td>...</td>\n",
       "      <td>312.188235</td>\n",
       "      <td>548.594150</td>\n",
       "      <td>380.725801</td>\n",
       "      <td>327.742856</td>\n",
       "      <td>552.001404</td>\n",
       "      <td>394.295247</td>\n",
       "      <td>318.250013</td>\n",
       "      <td>556.977247</td>\n",
       "      <td>387.425281</td>\n",
       "      <td>416.892736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28162.392168</td>\n",
       "      <td>28162.392168</td>\n",
       "      <td>107.325781</td>\n",
       "      <td>73.359786</td>\n",
       "      <td>1063.066706</td>\n",
       "      <td>3.059981</td>\n",
       "      <td>3237.071783</td>\n",
       "      <td>136.778361</td>\n",
       "      <td>3319.093794</td>\n",
       "      <td>1107.364849</td>\n",
       "      <td>...</td>\n",
       "      <td>1907.409140</td>\n",
       "      <td>2018.139532</td>\n",
       "      <td>1913.068860</td>\n",
       "      <td>1968.897065</td>\n",
       "      <td>2046.514519</td>\n",
       "      <td>1971.597698</td>\n",
       "      <td>1922.012651</td>\n",
       "      <td>2027.594079</td>\n",
       "      <td>1928.225395</td>\n",
       "      <td>573.119225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2137.000000</td>\n",
       "      <td>1.211765</td>\n",
       "      <td>2.001547</td>\n",
       "      <td>1.015984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33619.000000</td>\n",
       "      <td>33620.000000</td>\n",
       "      <td>3.897959</td>\n",
       "      <td>3.034742</td>\n",
       "      <td>3.568542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.414185</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.980399</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>35.893000</td>\n",
       "      <td>5.823876</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>35.499746</td>\n",
       "      <td>5.507186</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>35.566440</td>\n",
       "      <td>5.557000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52064.000000</td>\n",
       "      <td>52065.000000</td>\n",
       "      <td>7.866667</td>\n",
       "      <td>4.177778</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>188.723438</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>10.565528</td>\n",
       "      <td>0.869601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>94.057477</td>\n",
       "      <td>22.932013</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>95.451529</td>\n",
       "      <td>23.537593</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>96.148191</td>\n",
       "      <td>23.024000</td>\n",
       "      <td>206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>84495.000000</td>\n",
       "      <td>84496.000000</td>\n",
       "      <td>17.911111</td>\n",
       "      <td>10.718121</td>\n",
       "      <td>99.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>727.272807</td>\n",
       "      <td>1.001091</td>\n",
       "      <td>33.324890</td>\n",
       "      <td>3.557375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>90.622352</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>273.909000</td>\n",
       "      <td>93.032000</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>274.463844</td>\n",
       "      <td>91.906000</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105714.000000</td>\n",
       "      <td>105715.000000</td>\n",
       "      <td>7108.000000</td>\n",
       "      <td>14409.000000</td>\n",
       "      <td>127861.000000</td>\n",
       "      <td>327.808260</td>\n",
       "      <td>31967.592667</td>\n",
       "      <td>14659.578000</td>\n",
       "      <td>37498.200000</td>\n",
       "      <td>37495.420000</td>\n",
       "      <td>...</td>\n",
       "      <td>30892.912000</td>\n",
       "      <td>30892.912000</td>\n",
       "      <td>30892.912000</td>\n",
       "      <td>30892.912000</td>\n",
       "      <td>30892.912000</td>\n",
       "      <td>30892.912000</td>\n",
       "      <td>30878.017000</td>\n",
       "      <td>30878.017000</td>\n",
       "      <td>30878.017000</td>\n",
       "      <td>9009.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          Index           OTR           OCR  \\\n",
       "count   43817.000000   43817.000000  43817.000000  43817.000000   \n",
       "mean    57210.301618   57211.301618     28.384754     12.244495   \n",
       "std     28162.392168   28162.392168    107.325781     73.359786   \n",
       "min      2136.000000    2137.000000      1.211765      2.001547   \n",
       "25%     33619.000000   33620.000000      3.897959      3.034742   \n",
       "50%     52064.000000   52065.000000      7.866667      4.177778   \n",
       "75%     84495.000000   84496.000000     17.911111     10.718121   \n",
       "max    105714.000000  105715.000000   7108.000000  14409.000000   \n",
       "\n",
       "                 OMR  min_time_two_events  mean_time_two_events  \\\n",
       "count   43817.000000         43817.000000          43817.000000   \n",
       "mean      202.309402             0.102265           1329.763761   \n",
       "std      1063.066706             3.059981           3237.071783   \n",
       "min         1.015984             0.000000              0.003125   \n",
       "25%         3.568542             0.000000             73.414185   \n",
       "50%        16.000000             0.000000            188.723438   \n",
       "75%        99.200000             0.000000            727.272807   \n",
       "max    127861.000000           327.808260          31967.592667   \n",
       "\n",
       "       10_p_time_two_events  med_time_two_events  25_p_time_two_events  ...  \\\n",
       "count          43817.000000         43817.000000          43817.000000  ...   \n",
       "mean               4.158810           404.011596             67.036790  ...   \n",
       "std              136.778361          3319.093794           1107.364849  ...   \n",
       "min                0.000000             0.000000              0.000000  ...   \n",
       "25%                0.000003             2.980399              0.001456  ...   \n",
       "50%                0.000693            10.565528              0.869601  ...   \n",
       "75%                1.001091            33.324890              3.557375  ...   \n",
       "max            14659.578000         37498.200000          37495.420000  ...   \n",
       "\n",
       "       min_dt_TV1_TV2  mean_dt_TV1_TV2  med_dt_TV1_TV2  min_dt_TV1_TV3  \\\n",
       "count    43817.000000     43817.000000    43817.000000    43817.000000   \n",
       "mean       312.188235       548.594150      380.725801      327.742856   \n",
       "std       1907.409140      2018.139532     1913.068860     1968.897065   \n",
       "min          0.000001         0.000009        0.000001        0.000001   \n",
       "25%          0.000010        35.893000        5.823876        0.000010   \n",
       "50%          0.000343        94.057477       22.932013        0.000543   \n",
       "75%          0.001235       269.000000       90.622352        0.003882   \n",
       "max      30892.912000     30892.912000    30892.912000    30892.912000   \n",
       "\n",
       "       mean_dt_TV1_TV3  med_dt_TV1_TV3  min_dt_TV1_TV4  mean_dt_TV1_TV4  \\\n",
       "count     43817.000000    43817.000000    43817.000000     43817.000000   \n",
       "mean        552.001404      394.295247      318.250013       556.977247   \n",
       "std        2046.514519     1971.597698     1922.012651      2027.594079   \n",
       "min           0.000024        0.000003        0.000001         0.000009   \n",
       "25%          35.499746        5.507186        0.000033        35.566440   \n",
       "50%          95.451529       23.537593        0.000482        96.148191   \n",
       "75%         273.909000       93.032000        0.003898       274.463844   \n",
       "max       30892.912000    30892.912000    30878.017000     30878.017000   \n",
       "\n",
       "       med_dt_TV1_TV4  NbSecondWithAtLeatOneTrade  \n",
       "count    43817.000000                43817.000000  \n",
       "mean       387.425281                  416.892736  \n",
       "std       1928.225395                  573.119225  \n",
       "min          0.000003                    1.000000  \n",
       "25%          5.557000                   78.000000  \n",
       "50%         23.024000                  206.000000  \n",
       "75%         91.906000                  528.000000  \n",
       "max      30878.017000                 9009.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To have a wider view of the data that we are working with \n",
    "Data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Structure of the data*\n",
    "\n",
    "`Trading Venue = Platform where the trade is done`\n",
    "\n",
    "> ### Keys and identification\n",
    "\n",
    "1. *Index* in the dataset\n",
    "2. *Share* : Corresponding to the ISIN id of the security\n",
    "3. *Day* : Corresponding date id of the trade\n",
    "4. *Trader* : The market actor id for the trade : Trader \n",
    "\n",
    "> ### Events\n",
    "\n",
    "5. *Number of trades* On Trading Venue : OTR\n",
    "6. *Number of cancellation-type event* On TV1 : OCR\n",
    "7. *Number of modification-type event* On TV1 : OMR\n",
    "\n",
    "> ### Delta between two all-type events on Trading Venue 1\n",
    "\n",
    "8. *Min Delta* : min_time_two_events\n",
    "9. *Mean Delta* : mean_time_two_events\n",
    "10. *10th Percentile Delta* : 10_p_time_two_events\n",
    "11. *Median Delta Delta* : med_time_two_events\n",
    "12. *1st Quartile Delta* : 25_p_time_two_events\n",
    "13. *3rd Quartile Delta* : 75_p_time_two_events\n",
    "14. *90th Percentile Delta* : 90_p_time_two_events\n",
    "15. *Max Delta* : max_time_two_events\n",
    "\n",
    "> ### Statistics over the observed lifetime of cancelled orders on Trading Venue 1\n",
    "\n",
    "16. *Min lifetime* : min_lifetime_cancel\n",
    "17. *Mean lifetime* : mean_lifetime_cancel\n",
    "18. *10th Percentile lifetime* : 10_p_lifetime_cancel\n",
    "19. *Median lifetime* : med_lifetime_cancel\n",
    "20. *1st Quartile lifetime* : 25_p_lifetime_cancel\n",
    "21. *3rd Quartile lifetime* : 75_p_lifetime_cancel\n",
    "22. *90th Percentile lifetime* : 90_p_lifetime_cancel\n",
    "23. *Max lifetime* : max_lifetime_cancel\n",
    "---\n",
    "> ### Trade for all trading venues\n",
    "\n",
    "24. *Number of Trading Venues* on which the market player trades : NbTradeVenueMic\n",
    "25. *Max number of trade* from all trading venues : MaxNbTradesBySecond \n",
    "26. *Average number of trade* from all trading venues : MeanNbTradesBySecond\n",
    "---\n",
    "> ### Time Delta (dt) between two trades occuring on Trading Venue TV_1\n",
    "\n",
    "27. *Mean* : mean_dt_TV1\n",
    "28. *Median* : med_dt_TV1\n",
    "29. *Min* : min_dt_TV1\n",
    "---\n",
    "> ### Time Delta (dt) between two trades occuring on Trading Venue TV_1 then TV_2\n",
    "\n",
    "30.  *Mean* : mean_dt_TV1_TV2\n",
    "31.  *Median* : med_dt_TV1_TV2\n",
    "32.  *Min* : min_dt_TV1_TV2\n",
    "\n",
    "---\n",
    "> ### Time Delta (dt) between two trades occuring on Trading Venue TV_1 then TV_3\n",
    "\n",
    "33.  *Mean* : mean_dt_TV1_TV3\n",
    "34.  *Median* : med_dt_TV1_TV3\n",
    "35.  *Min* : min_dt_TV1_TV3\n",
    "---\n",
    "> ### Time Delta (dt) between two trades occuring on Trading Venue TV_1 then TV_4\n",
    "\n",
    "36.  *Mean* : mean_dt_TV1_TV4\n",
    "37.  *Median* : med_dt_TV1_TV4\n",
    "38.  *Min* : min_dt_TV1_TV4\n",
    "---\n",
    "> ###   From all trading venues\n",
    "\n",
    "39. *Number of seconds during the trading day where at least one trade of the market player i is observed* : NbSecondWithAtLeatOneTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of the types in y and their features in x\n",
    "x = Data.iloc[:,5:-1]\n",
    "y = Data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After spearating the dependent and independent variables we fit them into a pipeline of training to split the train and the test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.25, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocessing the data in the test and train environemet throughout scalling\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "sc_X = StandardScaler()\n",
    "x_train=sc_X.fit_transform(x_train)\n",
    "x_test=sc_X.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First of all we are going Multi-layer Perceptron classifier which is a classification algorithms that relies on an underlying Neural Network to perform the task of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPClassifier and the parameteres used\n",
    "clf = MLPClassifier(hidden_layer_sizes=(8,16,32), max_iter=100, alpha=0.0000001,\n",
    "                     solver='adam', verbose=10,  random_state=10,tol=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53820069\n",
      "Iteration 2, loss = 0.39153093\n",
      "Iteration 3, loss = 0.33829569\n",
      "Iteration 4, loss = 0.30688419\n",
      "Iteration 5, loss = 0.28769173\n",
      "Iteration 6, loss = 0.27332498\n",
      "Iteration 7, loss = 0.26167960\n",
      "Iteration 8, loss = 0.25320685\n",
      "Iteration 9, loss = 0.24473702\n",
      "Iteration 10, loss = 0.23832083\n",
      "Iteration 11, loss = 0.23283843\n",
      "Iteration 12, loss = 0.22835371\n",
      "Iteration 13, loss = 0.22455621\n",
      "Iteration 14, loss = 0.22108655\n",
      "Iteration 15, loss = 0.21735162\n",
      "Iteration 16, loss = 0.21398918\n",
      "Iteration 17, loss = 0.21071494\n",
      "Iteration 18, loss = 0.20756139\n",
      "Iteration 19, loss = 0.20517802\n",
      "Iteration 20, loss = 0.20255799\n",
      "Iteration 21, loss = 0.20154554\n",
      "Iteration 22, loss = 0.20107692\n",
      "Iteration 23, loss = 0.19945039\n",
      "Iteration 24, loss = 0.19659554\n",
      "Iteration 25, loss = 0.19537168\n",
      "Iteration 26, loss = 0.19411983\n",
      "Iteration 27, loss = 0.19262960\n",
      "Iteration 28, loss = 0.19110434\n",
      "Iteration 29, loss = 0.19010039\n",
      "Iteration 30, loss = 0.18836007\n",
      "Iteration 31, loss = 0.18785786\n",
      "Iteration 32, loss = 0.18603406\n",
      "Iteration 33, loss = 0.18515406\n",
      "Iteration 34, loss = 0.18361165\n",
      "Iteration 35, loss = 0.18284750\n",
      "Iteration 36, loss = 0.18142329\n",
      "Iteration 37, loss = 0.18026287\n",
      "Iteration 38, loss = 0.17950704\n",
      "Iteration 39, loss = 0.17805505\n",
      "Iteration 40, loss = 0.17715288\n",
      "Iteration 41, loss = 0.17496007\n",
      "Iteration 42, loss = 0.17535649\n",
      "Iteration 43, loss = 0.17344849\n",
      "Iteration 44, loss = 0.17323453\n",
      "Iteration 45, loss = 0.17197956\n",
      "Iteration 46, loss = 0.17148368\n",
      "Iteration 47, loss = 0.17066370\n",
      "Iteration 48, loss = 0.17011497\n",
      "Iteration 49, loss = 0.16913634\n",
      "Iteration 50, loss = 0.17239498\n",
      "Iteration 51, loss = 0.16726646\n",
      "Iteration 52, loss = 0.16687827\n",
      "Iteration 53, loss = 0.16713443\n",
      "Iteration 54, loss = 0.16609840\n",
      "Iteration 55, loss = 0.16530783\n",
      "Iteration 56, loss = 0.16649393\n",
      "Iteration 57, loss = 0.16493822\n",
      "Iteration 58, loss = 0.16486050\n",
      "Iteration 59, loss = 0.16387860\n",
      "Iteration 60, loss = 0.16332074\n",
      "Iteration 61, loss = 0.16222414\n",
      "Iteration 62, loss = 0.16220393\n",
      "Iteration 63, loss = 0.16186618\n",
      "Iteration 64, loss = 0.16078469\n",
      "Iteration 65, loss = 0.16172151\n",
      "Iteration 66, loss = 0.16113472\n",
      "Iteration 67, loss = 0.16028581\n",
      "Iteration 68, loss = 0.15932554\n",
      "Iteration 69, loss = 0.15901562\n",
      "Iteration 70, loss = 0.15820474\n",
      "Iteration 71, loss = 0.15903764\n",
      "Iteration 72, loss = 0.15857696\n",
      "Iteration 73, loss = 0.15845780\n",
      "Iteration 74, loss = 0.15651880\n",
      "Iteration 75, loss = 0.15593312\n",
      "Iteration 76, loss = 0.15559866\n",
      "Iteration 77, loss = 0.15488357\n",
      "Iteration 78, loss = 0.15462404\n",
      "Iteration 79, loss = 0.15557504\n",
      "Iteration 80, loss = 0.15508330\n",
      "Iteration 81, loss = 0.15452233\n",
      "Iteration 82, loss = 0.15339395\n",
      "Iteration 83, loss = 0.15315867\n",
      "Iteration 84, loss = 0.15415263\n",
      "Iteration 85, loss = 0.15262203\n",
      "Iteration 86, loss = 0.15273353\n",
      "Iteration 87, loss = 0.15281480\n",
      "Iteration 88, loss = 0.15177607\n",
      "Iteration 89, loss = 0.15167367\n",
      "Iteration 90, loss = 0.15091292\n",
      "Iteration 91, loss = 0.14999938\n",
      "Iteration 92, loss = 0.15034168\n",
      "Iteration 93, loss = 0.15027390\n",
      "Iteration 94, loss = 0.14980369\n",
      "Iteration 95, loss = 0.14944745\n",
      "Iteration 96, loss = 0.15023373\n",
      "Iteration 97, loss = 0.14822858\n",
      "Iteration 98, loss = 0.14851830\n",
      "Iteration 99, loss = 0.14805632\n",
      "Iteration 100, loss = 0.14849705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yousef/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved a high accuracy score which means that the dataset fits well the model and that the model will be able to predict the type of trader 95% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945778183477864"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we have decide to use a Logistic Regression model which is used to predict the probability of a categorical dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yousef/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that in the Logistic Regression Model the dependent variable is a binary variable that contains data coded as 1  or 0, the model has scored less than MLP but an over all good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681880419899589"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have decided to a Random Forest Classifier which meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion ='entropy', random_state=0)\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that the features of the random forest model which control over-fitting and improve the predictive accuracy this model has scored the highest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840255591054313"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that all models work well as they have all achieved an accuracy rate of over 75%, but the random forest model and the MLP Classifier are more recommended when multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
